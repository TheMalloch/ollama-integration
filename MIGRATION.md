# Guide de Migration - Architecture Modulaire Ollama

## ğŸ“‹ Vue d'ensemble

Cette migration transforme l'extension Ollama en une architecture modulaire complÃ¨te avec des fonctionnalitÃ©s avancÃ©es d'analyse de projet, de gestion de contexte et de gÃ©nÃ©ration de ModelFiles spÃ©cialisÃ©s.

## ğŸ”„ Changements Structurels

### Ancien Fichier vs Nouvelle Architecture

```
AVANT:
src/
â”œâ”€â”€ extension.ts          (monolithe)
â”œâ”€â”€ chatProvider.ts      
â””â”€â”€ ollamaService.ts

APRÃˆS:
src/
â”œâ”€â”€ extension-new.ts              (nouvelle implÃ©mentation)
â”œâ”€â”€ interfaces/
â”‚   â””â”€â”€ IChatProvider.ts         (interfaces TypeScript)
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ context/
â”‚   â”‚   â””â”€â”€ contextManager.ts    (gestion contexte)
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â””â”€â”€ modelFileGenerator.ts (gÃ©nÃ©ration ModelFiles)
â”‚   â””â”€â”€ analysis/
â”‚       â””â”€â”€ codeAnalyzer.ts      (analyse de code)
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ projectDetector.ts       (dÃ©tection projets)
â”‚   â””â”€â”€ fileUtils.ts            (utilitaires fichiers)
â”œâ”€â”€ chatProvider.ts              (mis Ã  jour)
â””â”€â”€ ollamaService.ts
```

## ğŸ¯ Nouvelles FonctionnalitÃ©s

### 1. DÃ©tection Automatique de Projet
- **Framework Detection**: React, Vue, Angular, Express, NestJS, etc.
- **Architecture Patterns**: MVC, MVVM, Clean Architecture
- **Build Tools**: Webpack, Vite, Rollup, Parcel
- **Package Managers**: npm, yarn, pnpm

### 2. Gestion de Contexte Persistant
- **Sauvegarde JSON**: Stockage dans `.ollama-context/`
- **Analyse Dependencies**: Graphe de dÃ©pendances automatique
- **Export Multi-LLM**: OpenAI, Anthropic, Generic formats
- **Backup & Restore**: Sauvegarde automatique du contexte

### 3. GÃ©nÃ©ration ModelFile SpÃ©cialisÃ©
- **Mode Debug**: OptimisÃ© pour le dÃ©bogage
- **Mode Development**: Pour le dÃ©veloppement actif
- **Mode Review**: Pour la revue de code
- **Mode Optimization**: Pour l'optimisation

## ğŸš€ Nouvelles Commandes

### Commands Palette (Ctrl+Shift+P)
```
Ollama: Analyze Project Structure    â†’ Analyse complÃ¨te du projet
Ollama: Export Project Context       â†’ Export contexte multi-format
Ollama: Generate Specialized Model   â†’ CrÃ©ation ModelFile spÃ©cialisÃ©
Ollama: Clear Project Context        â†’ Nettoyage du contexte
Ollama: Show Context Summary         â†’ RÃ©sumÃ© du contexte actuel
```

### Context Menu (Clic droit)
```
Send to Ollama (Basic)              â†’ Mode basique original
Send to Ollama (Full Context)       â†’ Avec contexte complet
Send to Ollama (Project Aware)      â†’ Avec analyse projet
```

## âš™ï¸ Configuration AvancÃ©e

### Nouvelles Configurations dans settings.json
```json
{
  "ollama.useFullContext": true,
  "ollama.contextStorage.enabled": true,
  "ollama.contextStorage.path": ".ollama-context",
  "ollama.projectDetection.enabled": true,
  "ollama.modelFile.autoGenerate": true,
  "ollama.response.maxTokens": "adaptive",
  "ollama.response.format": "structured"
}
```

### Configuration Adaptative
- **maxTokens: "adaptive"**: S'ajuste automatiquement selon la taille du projet
- **response.format**: 
  - `structured`: Avec sections organisÃ©es
  - `markdown`: Format markdown standard
  - `plain`: Texte brut

## ğŸ“ Structure de Contexte

### Fichier `.ollama-context/project-context.json`
```json
{
  "metadata": {
    "type": "web",
    "language": "typescript",
    "frameworks": [
      {
        "name": "React",
        "version": "18.2.0",
        "type": "frontend",
        "confidence": 95
      }
    ],
    "buildTools": ["vite", "typescript"],
    "packageManager": "npm"
  },
  "dependencies": {
    "local": [...],
    "external": [...],
    "tree": [...]
  },
  "structure": {
    "components": [...],
    "services": [...],
    "utilities": [...]
  },
  "exports": {
    "ollama": "ModelFile optimisÃ© pour ce projet",
    "openai": "Contexte format OpenAI",
    "anthropic": "Contexte format Claude"
  }
}
```

## ğŸ”§ API et Interfaces

### IChatProvider Interface
```typescript
interface IChatProvider {
    addUserMessage(message: string): void;
    clearChat(): void;
    updateContextSetting(enabled: boolean): void;
    updateProjectContext(context: ProjectContext): void;
}
```

### Utilisation Programmatique
```typescript
import { ProjectDetector } from './utils/projectDetector';
import { ContextManager } from './core/context/contextManager';
import { ModelFileGenerator } from './core/llm/modelFileGenerator';

// DÃ©tecter le projet
const detector = new ProjectDetector(workspaceFolder);
const metadata = await detector.detectProject();

// GÃ©rer le contexte
const contextManager = new ContextManager(workspaceFolder);
await contextManager.loadOrCreateContext();

// GÃ©nÃ©rer ModelFile
const generator = new ModelFileGenerator();
const modelFile = await generator.generateModelFile(context, 'development');
```

## ğŸ¨ Interface Utilisateur

### Status Bar AmÃ©liorÃ©e
- **Basic Mode**: `$(file-text) Ollama Basic`
- **Context Mode**: `$(file-text) Contexte: React App`
- **Analysis Mode**: `$(sync~spin) Analyse en cours...`

### Messages de Contexte
L'interface chat affiche maintenant:
- Type de projet dÃ©tectÃ©
- Frameworks utilisÃ©s
- Outils de build
- ComplexitÃ© estimÃ©e

## ğŸ“Š MÃ©triques et Performance

### Optimisations
- **Lazy Loading**: Modules chargÃ©s Ã  la demande
- **Cache Intelligent**: RÃ©utilisation des analyses
- **Token Adaptatif**: Limite dynamique selon le projet
- **Compression**: Contexte optimisÃ© pour les LLM

### Monitoring
- Taille du contexte gÃ©nÃ©rÃ©e
- Temps d'analyse du projet
- Utilisation mÃ©moire optimisÃ©e
- Logs dÃ©taillÃ©s en mode debug

## ğŸ› ï¸ Migration Ã‰tapes

### 1. Backup (RecommandÃ©)
```bash
# Sauvegarder l'ancien code
cp src/extension.ts src/extension.backup.ts
```

### 2. Activation Nouvelle Architecture
```bash
# Renommer pour activer
mv src/extension.ts src/extension.old.ts
mv src/extension-new.ts src/extension.ts
```

### 3. Configuration Initiale
1. Ouvrir VS Code Settings (Ctrl+,)
2. Rechercher "ollama"
3. Activer les nouvelles fonctionnalitÃ©s
4. Configurer le chemin de stockage contexte

### 4. Test Initial
1. Ouvrir Command Palette (Ctrl+Shift+P)
2. Lancer "Ollama: Analyze Project Structure"
3. VÃ©rifier la gÃ©nÃ©ration de `.ollama-context/`
4. Tester les nouvelles commandes

## ğŸ› DÃ©pannage

### ProblÃ¨mes Courants

#### Contexte Non GÃ©nÃ©rÃ©
- VÃ©rifier permissions dossier workspace
- S'assurer que `contextStorage.enabled: true`
- RedÃ©marrer VS Code

#### DÃ©tection Projet Ã‰choue
- VÃ©rifier prÃ©sence package.json/requirements.txt
- Logs dans Output Panel â†’ "Ollama Integration"
- Mode debug pour traces dÃ©taillÃ©es

#### ModelFile Non CrÃ©Ã©
- VÃ©rifier connexion serveur Ollama
- S'assurer modÃ¨le base disponible
- VÃ©rifier configuration `modelFile.autoGenerate`

### Logs et Debug
```typescript
// Activer logs dÃ©taillÃ©s
"ollama.debug": true

// Voir logs dans Output Panel
// View â†’ Output â†’ Select "Ollama Integration"
```

## ğŸ”® Prochaines Ã‰tapes

### FonctionnalitÃ©s PlanifiÃ©es
- [ ] Interface graphique pour ModelFile editing
- [ ] Export vers d'autres LLM providers
- [ ] Analyse sÃ©mantique avancÃ©e du code
- [ ] Templates de ModelFile personnalisables
- [ ] IntÃ©gration Git pour contexte historique

### Contributions
Le code est maintenant modulaire et extensible. Chaque composant peut Ãªtre dÃ©veloppÃ© indÃ©pendamment :

- `utils/` : DÃ©tection et analyse
- `core/` : Logique mÃ©tier principale  
- `interfaces/` : Contrats TypeScript

---

## ğŸ“ Support

Pour toute question sur la migration :
1. VÃ©rifier ce guide
2. Consulter les logs dans Output Panel
3. Tester avec `test-features.js`
4. Comparer avec `extension.old.ts` si nÃ©cessaire

**L'architecture modulaire est maintenant prÃªte ! ğŸ‰**
